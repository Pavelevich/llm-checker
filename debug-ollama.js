const OllamaClient = require('./src/ollama/client');

async function diagnoseOllama() {
    console.log('üîç Diagnosing Ollama connection...\n');
    
    const client = new OllamaClient();
    
    try {
        // Test completo de conexi√≥n
        const testResult = await client.testConnection();
        
        if (testResult.success) {
            console.log('‚úÖ Ollama connection successful!');
            console.log(`   Version: ${testResult.version}`);
            console.log(`   Models found: ${testResult.modelsFound}`);
            
            if (testResult.modelsFound === 0) {
                console.log('\nüí° No models installed. Try installing one:');
                console.log('   ollama pull tinyllama');
                console.log('   ollama pull llama3.2:3b');
            } else {
                console.log('\nüì¶ Installed models:');
                testResult.models.forEach(model => {
                    console.log(`   ‚Ä¢ ${model.name}`);
                });
            }
        } else {
            console.log('‚ùå Ollama connection failed');
            console.log(`   Error: ${testResult.error}`);
            console.log(`   Details: ${testResult.details}`);
            
            console.log('\nüîß Possible solutions:');
            console.log('1. Install Ollama: curl -fsSL https://ollama.ai/install.sh | sh');
            console.log('2. Start Ollama: ollama serve');
            console.log('3. Check if running: curl http://localhost:11434/api/version');
        }
    } catch (error) {
        console.log('‚ùå Diagnosis failed:', error.message);
    }
}

diagnoseOllama();
